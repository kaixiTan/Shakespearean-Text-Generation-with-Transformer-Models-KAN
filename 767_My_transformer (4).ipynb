{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeUKE5ZXv4Go"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import collections\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Lambda\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/767project/Shakespeare_data.csv\")"
      ],
      "metadata": {
        "id": "5JPHCbUzwEdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "RS58Y0zBwSZa",
        "outputId": "66edd139-2c2e-4149-8bbe-8ea059d050df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
              "0         1  Henry IV               NaN          NaN            NaN   \n",
              "1         2  Henry IV               NaN          NaN            NaN   \n",
              "2         3  Henry IV               NaN          NaN            NaN   \n",
              "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
              "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
              "\n",
              "                                          PlayerLine  \n",
              "0                                              ACT I  \n",
              "1                       SCENE I. London. The palace.  \n",
              "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
              "3             So shaken as we are, so wan with care,  \n",
              "4         Find we a time for frighted peace to pant,  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a5f1b0b-064d-463a-9e6e-8af5b98d06e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a5f1b0b-064d-463a-9e6e-8af5b98d06e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a5f1b0b-064d-463a-9e6e-8af5b98d06e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a5f1b0b-064d-463a-9e6e-8af5b98d06e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4cf85fc-b98b-4ec6-9f2e-eacf9be49fb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4cf85fc-b98b-4ec6-9f2e-eacf9be49fb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4cf85fc-b98b-4ec6-9f2e-eacf9be49fb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data['PlayerLine']\n",
        "subset_size = int(len(dataset) * 0.10)\n",
        "subset_indices = np.random.choice(range(len(dataset)), size=subset_size, replace=False)\n",
        "subset_dataset = dataset[subset_indices]\n",
        "dataset = subset_dataset"
      ],
      "metadata": {
        "id": "UEgqBenewTPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "with strategy.scope():\n",
        "    for line in dataset:\n",
        "        lowercase_line = line.lower()\n",
        "        corpus.append(lowercase_line)\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US1o8bw6wViq",
        "outputId": "c61db0e4-d148-49e0-c7e1-ca0582413a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scene i. the english camp at agincourt.',\n",
              " 'fond done, done fond,',\n",
              " 'damnation: but this is not so: the king is not',\n",
              " 'exeunt',\n",
              " 'hautboys',\n",
              " 'now let hot aetna cool in sicily,',\n",
              " 'dumb, yet are they much too light for the bore of',\n",
              " 'a fever with the absence of her son,',\n",
              " 'with her her niece, the lady blanch of spain,',\n",
              " 'and meet me presently at salisbury.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_to_token = tokenizer.word_index\n",
        "def key_pair(num):\n",
        "    count=0\n",
        "    for key, value in word_to_token.items():\n",
        "        if count>=num: break\n",
        "        print(f''''{key:}': {value},''')\n",
        "        count +=1\n",
        "key_pair(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSabxGVHwXHB",
        "outputId": "ce204029-4b30-42f5-aac0-f582e99b4a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'the': 1,\n",
            "'and': 2,\n",
            "'i': 3,\n",
            "'to': 4,\n",
            "'of': 5,\n",
            "'a': 6,\n",
            "'you': 7,\n",
            "'my': 8,\n",
            "'in': 9,\n",
            "'that': 10,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "with strategy.scope():\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n"
      ],
      "metadata": {
        "id": "yLhmP9WKwfCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuEC2MKbwk4j",
        "outputId": "2813713b-178a-42da-e854-d8836ec56728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[111, 3],\n",
              " [111, 3, 1],\n",
              " [111, 3, 1, 525],\n",
              " [111, 3, 1, 525, 700],\n",
              " [111, 3, 1, 525, 700, 46]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = input_sequences[1]\n",
        "max_seq_len = max(len(x) for x in input_sequences)\n",
        "print(max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCpRJwY0w6b7",
        "outputId": "34623dcc-5590-4ab5-f691-3031ae30387c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(word_to_token)+1\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SroLMMpZxOZi",
        "outputId": "20c4fa2f-708e-454c-f832-23be78d14470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding = 'pre'))\n",
        "after = input_sequences[1]"
      ],
      "metadata": {
        "id": "0Q6RTBngwp6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Before: {before}')\n",
        "print(f'After: {after}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMepKKNMw8bK",
        "outputId": "877c1245-03ee-4300-d339-2e3267e68607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [111, 3, 1]\n",
            "After: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0 111   3   1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = input_sequences[:, :-1], input_sequences[:, -1],\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "HJvG5FHCxGhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMfeoYV1cncR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_model_modified(total_words, max_seq_len):\n",
        "\n",
        "    d_model = 64\n",
        "    num_heads = 4\n",
        "    ff_dim = 128\n",
        "\n",
        "    # input Layer\n",
        "    inputs = Input(shape=(max_seq_len-1,))\n",
        "    # word embedding\n",
        "    embedding_layer = Embedding(total_words, d_model)(inputs)\n",
        "\n",
        "    # Muti head attention\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer)\n",
        "    # connection\n",
        "    attn_output = tf.keras.layers.Add()([attn_output, embedding_layer])\n",
        "    # Normailzation\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "\n",
        "    # feed forward network\n",
        "    ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
        "\n",
        "    ffn_output = tf.keras.layers.Add()([ffn_output, attn_output])\n",
        "    # Normailzation\n",
        "    seq_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(ffn_output)\n",
        "\n",
        "    # outputlayer\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "eCOI_1FgcmeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = transformer_model_modified(total_words, max_seq_len)"
      ],
      "metadata": {
        "id": "pS9Ps9D_kQQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss=CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "transformer_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlalK1kkc1QB",
        "outputId": "edf75278-8761-4cd9-bec8-01f16813ca7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 47)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)     (None, 47, 64)               577472    ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, 47, 64)               66368     ['embedding_5[0][0]',         \n",
            " ltiHeadAttention)                                                   'embedding_5[0][0]']         \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 47, 64)               0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'embedding_5[0][0]']         \n",
            "                                                                                                  \n",
            " layer_normalization_10 (La  (None, 47, 64)               128       ['add_10[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 47, 128)              8320      ['layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 47, 64)               8256      ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 47, 64)               0         ['dense_15[0][0]',            \n",
            "                                                                     'layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_11 (La  (None, 47, 64)               128       ['add_11[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)           (None, 64)                   0         ['layer_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 9023)                 586495    ['lambda_4[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1247167 (4.76 MB)\n",
            "Trainable params: 1247167 (4.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8\n",
        "history = transformer_model.fit(features, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOjAnviveHQC",
        "outputId": "e41ba473-890a-4db9-853b-c97da26bed27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8894/8894 [==============================] - 117s 12ms/step - loss: 6.8580 - accuracy: 0.0572\n",
            "Epoch 2/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 6.1809 - accuracy: 0.0903\n",
            "Epoch 3/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 5.7922 - accuracy: 0.1158\n",
            "Epoch 4/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 5.4872 - accuracy: 0.1417\n",
            "Epoch 5/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 5.2501 - accuracy: 0.1561\n",
            "Epoch 6/50\n",
            "8894/8894 [==============================] - 103s 12ms/step - loss: 5.0742 - accuracy: 0.1641\n",
            "Epoch 7/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 4.9367 - accuracy: 0.1710\n",
            "Epoch 8/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 4.8095 - accuracy: 0.1796\n",
            "Epoch 9/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 4.6840 - accuracy: 0.1928\n",
            "Epoch 10/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 4.5459 - accuracy: 0.2067\n",
            "Epoch 11/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 4.4056 - accuracy: 0.2219\n",
            "Epoch 12/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 4.2520 - accuracy: 0.2408\n",
            "Epoch 13/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 4.1039 - accuracy: 0.2595\n",
            "Epoch 14/50\n",
            "8894/8894 [==============================] - 113s 13ms/step - loss: 3.9587 - accuracy: 0.2778\n",
            "Epoch 15/50\n",
            "8894/8894 [==============================] - 111s 12ms/step - loss: 3.8279 - accuracy: 0.2946\n",
            "Epoch 16/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 3.7089 - accuracy: 0.3111\n",
            "Epoch 17/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 3.5968 - accuracy: 0.3265\n",
            "Epoch 18/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 3.4947 - accuracy: 0.3432\n",
            "Epoch 19/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 3.4110 - accuracy: 0.3542\n",
            "Epoch 20/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 3.3352 - accuracy: 0.3630\n",
            "Epoch 21/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 3.2740 - accuracy: 0.3741\n",
            "Epoch 22/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 3.2052 - accuracy: 0.3831\n",
            "Epoch 23/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 3.1526 - accuracy: 0.3942\n",
            "Epoch 24/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 3.0975 - accuracy: 0.3994\n",
            "Epoch 25/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 3.0533 - accuracy: 0.4081\n",
            "Epoch 26/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 3.0140 - accuracy: 0.4144\n",
            "Epoch 27/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 2.9683 - accuracy: 0.4219\n",
            "Epoch 28/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.9389 - accuracy: 0.4266\n",
            "Epoch 29/50\n",
            "8894/8894 [==============================] - 105s 12ms/step - loss: 2.8972 - accuracy: 0.4323\n",
            "Epoch 30/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 2.8727 - accuracy: 0.4364\n",
            "Epoch 31/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.8311 - accuracy: 0.4451\n",
            "Epoch 32/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 2.8109 - accuracy: 0.4457\n",
            "Epoch 33/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.7922 - accuracy: 0.4496\n",
            "Epoch 34/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.7660 - accuracy: 0.4536\n",
            "Epoch 35/50\n",
            "8894/8894 [==============================] - 98s 11ms/step - loss: 2.7342 - accuracy: 0.4598\n",
            "Epoch 36/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.7227 - accuracy: 0.4625\n",
            "Epoch 37/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 2.7005 - accuracy: 0.4641\n",
            "Epoch 38/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.6763 - accuracy: 0.4670\n",
            "Epoch 39/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.6596 - accuracy: 0.4718\n",
            "Epoch 40/50\n",
            "8894/8894 [==============================] - 101s 11ms/step - loss: 2.6411 - accuracy: 0.4752\n",
            "Epoch 41/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 2.6247 - accuracy: 0.4773\n",
            "Epoch 42/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 2.6166 - accuracy: 0.4801\n",
            "Epoch 43/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 2.5929 - accuracy: 0.4808\n",
            "Epoch 44/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.5744 - accuracy: 0.4842\n",
            "Epoch 45/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.5676 - accuracy: 0.4852\n",
            "Epoch 46/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.5546 - accuracy: 0.4882\n",
            "Epoch 47/50\n",
            "8894/8894 [==============================] - 103s 12ms/step - loss: 2.5419 - accuracy: 0.4900\n",
            "Epoch 48/50\n",
            "8894/8894 [==============================] - 99s 11ms/step - loss: 2.5255 - accuracy: 0.4938\n",
            "Epoch 49/50\n",
            "8894/8894 [==============================] - 100s 11ms/step - loss: 2.5208 - accuracy: 0.4933\n",
            "Epoch 50/50\n",
            "8894/8894 [==============================] - 98s 11ms/step - loss: 2.5129 - accuracy: 0.4951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_generator(model, string, num):\n",
        "    if len(string) == 0:\n",
        "        print(\"Error: No word found\")\n",
        "        return\n",
        "\n",
        "    for _ in range(num):\n",
        "        token_list = tokenizer.texts_to_sequences([string])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding=\"pre\")\n",
        "        # Predict the next word base on model\n",
        "        probabilities = model.predict(token_list)[0]\n",
        "        # Use the highest probability words\n",
        "        predicted = np.argmax(probabilities)\n",
        "        if predicted != 0:\n",
        "            generated_word = tokenizer.index_word[predicted]\n",
        "            string += \" \" + generated_word\n",
        "\n",
        "    print(string)"
      ],
      "metadata": {
        "id": "qJXx2s8ZldNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model, \"long live the king\", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs6__At65hEL",
        "outputId": "26d6bc09-6f59-41df-8377-1a3a66b45115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "long live the king enlarge happy habiliment fee lint boast nay 'this perverseness tread\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model, \"Wherefore art thou \", 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "somc8IAs537j",
        "outputId": "b9e98118-6497-4e05-db9d-3ed0730ca650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Wherefore art thou  deform'd seed meet grave mistaken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model, \"thee\", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-1n0W8ogSjM",
        "outputId": "0c871151-0df3-4d35-fb35-b84619287e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "thee shrinking maps dined beseech false wild erring will't virtues came\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('fasttext-wiki-news-subwords-300')\n",
        "\n",
        "\n",
        "print(model.most_similar('apple'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-2ydztF9qkK",
        "outputId": "b8e0ec5c-354e-4b60-f54c-47fb855dd7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "[('apples', 0.8046640753746033), ('pear', 0.6897592544555664), ('peach', 0.6626990437507629), ('fruit', 0.6596963405609131), ('apple-', 0.6546189785003662), ('appley', 0.6466962099075317), ('pippin', 0.6454442143440247), ('pome', 0.6110042333602905), ('apple-tree', 0.6037725210189819), ('berry', 0.602673351764679)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((total_words, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if word in model:\n",
        "        embedding_vector = model[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "id": "IeWa_eKQATEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def transformer_model_modified_FastText(total_words, max_seq_len):\n",
        "    d_model = 300\n",
        "    num_heads = 4\n",
        "    ff_dim = 128\n",
        "\n",
        "    inputs = Input(shape=(max_seq_len-1,))\n",
        "\n",
        "    # FastText Word embedding\n",
        "    embedding_layer = Embedding(total_words, d_model, weights=[embedding_matrix], trainable=False)(inputs)\n",
        "    # Muti head attention\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer)\n",
        "    # connection\n",
        "    attn_output = tf.keras.layers.Add()([attn_output, embedding_layer])\n",
        "    # Normailzation\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "\n",
        "    # feed forward network\n",
        "    ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
        "\n",
        "    ffn_output = tf.keras.layers.Add()([ffn_output, attn_output])\n",
        "    # Normailzation\n",
        "    seq_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(ffn_output)\n",
        "\n",
        "    # outputlayer\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "hkeAs6bxAdh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Model\n",
        "transformer_model_modified_FastText = transformer_model_modified_FastText(total_words, max_seq_len)\n",
        "\n",
        "transformer_model_modified_FastText.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "transformer_model_modified_FastText.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPufSrDLA5Xz",
        "outputId": "c577ace4-d304-435d-cdc7-8a8c7416e24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 67)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 67, 300)              2709000   ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 67, 300)              1443900   ['embedding_2[0][0]',         \n",
            " ltiHeadAttention)                                                   'embedding_2[0][0]']         \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 67, 300)              0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'embedding_2[0][0]']         \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 67, 300)              600       ['add_4[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 67, 128)              38528     ['layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 67, 300)              38700     ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 67, 300)              0         ['dense_7[0][0]',             \n",
            "                                                                     'layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 67, 300)              600       ['add_5[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 300)                  0         ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 9030)                 2718030   ['lambda_2[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6949358 (26.51 MB)\n",
            "Trainable params: 4240358 (16.18 MB)\n",
            "Non-trainable params: 2709000 (10.33 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fasttext model training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8\n",
        "history = transformer_model_modified_FastText.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = transformer_model_modified_FastText.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SvfBlFsBSHb",
        "outputId": "5998de52-e320-4bb6-bbb8-ca7022814bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7084/7084 [==============================] - 62s 8ms/step - loss: 6.8483 - accuracy: 0.0637 - val_loss: 6.7170 - val_accuracy: 0.0686\n",
            "Epoch 2/50\n",
            "7084/7084 [==============================] - 57s 8ms/step - loss: 6.1312 - accuracy: 0.0771 - val_loss: 6.8041 - val_accuracy: 0.0762\n",
            "Epoch 3/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.8393 - accuracy: 0.0809 - val_loss: 6.9233 - val_accuracy: 0.0815\n",
            "Epoch 4/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.6278 - accuracy: 0.0846 - val_loss: 7.0005 - val_accuracy: 0.0714\n",
            "Epoch 5/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.4528 - accuracy: 0.0884 - val_loss: 7.0457 - val_accuracy: 0.0723\n",
            "Epoch 6/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.3088 - accuracy: 0.0933 - val_loss: 7.1363 - val_accuracy: 0.0730\n",
            "Epoch 7/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.1851 - accuracy: 0.0990 - val_loss: 7.1613 - val_accuracy: 0.0714\n",
            "Epoch 8/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.0660 - accuracy: 0.1038 - val_loss: 7.2605 - val_accuracy: 0.0704\n",
            "Epoch 9/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.9410 - accuracy: 0.1103 - val_loss: 7.3139 - val_accuracy: 0.0720\n",
            "Epoch 10/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.8241 - accuracy: 0.1184 - val_loss: 7.4066 - val_accuracy: 0.0672\n",
            "Epoch 11/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.7160 - accuracy: 0.1264 - val_loss: 7.4636 - val_accuracy: 0.0703\n",
            "Epoch 12/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.6207 - accuracy: 0.1322 - val_loss: 7.5921 - val_accuracy: 0.0682\n",
            "Epoch 13/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.5265 - accuracy: 0.1407 - val_loss: 7.7351 - val_accuracy: 0.0615\n",
            "Epoch 14/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.4427 - accuracy: 0.1482 - val_loss: 7.7836 - val_accuracy: 0.0621\n",
            "Epoch 15/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.3774 - accuracy: 0.1524 - val_loss: 7.7696 - val_accuracy: 0.0632\n",
            "Epoch 16/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.3014 - accuracy: 0.1614 - val_loss: 7.8644 - val_accuracy: 0.0610\n",
            "Epoch 17/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.2455 - accuracy: 0.1666 - val_loss: 7.9735 - val_accuracy: 0.0558\n",
            "Epoch 18/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.1873 - accuracy: 0.1728 - val_loss: 7.9816 - val_accuracy: 0.0625\n",
            "Epoch 19/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.1386 - accuracy: 0.1814 - val_loss: 7.9798 - val_accuracy: 0.0621\n",
            "Epoch 20/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.0923 - accuracy: 0.1850 - val_loss: 7.9451 - val_accuracy: 0.0655\n",
            "Epoch 21/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.0447 - accuracy: 0.1931 - val_loss: 8.1245 - val_accuracy: 0.0531\n",
            "Epoch 22/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.0033 - accuracy: 0.1978 - val_loss: 8.0887 - val_accuracy: 0.0566\n",
            "Epoch 23/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.9589 - accuracy: 0.2022 - val_loss: 8.1134 - val_accuracy: 0.0627\n",
            "Epoch 24/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.9181 - accuracy: 0.2086 - val_loss: 8.1630 - val_accuracy: 0.0505\n",
            "Epoch 25/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.8734 - accuracy: 0.2147 - val_loss: 8.1991 - val_accuracy: 0.0563\n",
            "Epoch 26/50\n",
            "7082/7084 [============================>.] - ETA: 0s - loss: 3.8394 - accuracy: 0.2200Epoch 27/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.8003 - accuracy: 0.2228 - val_loss: 8.4825 - val_accuracy: 0.0551\n",
            "Epoch 28/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.7662 - accuracy: 0.2295 - val_loss: 8.2432 - val_accuracy: 0.0512\n",
            "Epoch 29/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.7463 - accuracy: 0.2319 - val_loss: 8.2779 - val_accuracy: 0.0599\n",
            "Epoch 30/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.7027 - accuracy: 0.2379 - val_loss: 8.3359 - val_accuracy: 0.0583\n",
            "Epoch 31/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6780 - accuracy: 0.2407 - val_loss: 8.4604 - val_accuracy: 0.0524\n",
            "Epoch 32/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6440 - accuracy: 0.2474 - val_loss: 8.4596 - val_accuracy: 0.0484\n",
            "Epoch 33/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6048 - accuracy: 0.2527 - val_loss: 8.4559 - val_accuracy: 0.0556\n",
            "Epoch 34/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5792 - accuracy: 0.2584 - val_loss: 8.4389 - val_accuracy: 0.0551\n",
            "Epoch 35/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5482 - accuracy: 0.2616 - val_loss: 8.7203 - val_accuracy: 0.0494\n",
            "Epoch 36/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5175 - accuracy: 0.2660 - val_loss: 8.6752 - val_accuracy: 0.0521\n",
            "Epoch 37/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4912 - accuracy: 0.2688 - val_loss: 8.6387 - val_accuracy: 0.0541\n",
            "Epoch 38/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4603 - accuracy: 0.2744 - val_loss: 8.7575 - val_accuracy: 0.0559\n",
            "Epoch 39/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4378 - accuracy: 0.2782 - val_loss: 8.8746 - val_accuracy: 0.0456\n",
            "Epoch 40/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4092 - accuracy: 0.2834 - val_loss: 8.7051 - val_accuracy: 0.0541\n",
            "Epoch 41/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3840 - accuracy: 0.2861 - val_loss: 8.7872 - val_accuracy: 0.0515\n",
            "Epoch 42/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3566 - accuracy: 0.2912 - val_loss: 8.8049 - val_accuracy: 0.0539\n",
            "Epoch 43/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3297 - accuracy: 0.2971 - val_loss: 8.7584 - val_accuracy: 0.0580\n",
            "Epoch 44/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2983 - accuracy: 0.3007 - val_loss: 8.9334 - val_accuracy: 0.0511\n",
            "Epoch 45/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2759 - accuracy: 0.3027 - val_loss: 8.9677 - val_accuracy: 0.0495\n",
            "Epoch 46/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2466 - accuracy: 0.3075 - val_loss: 8.8484 - val_accuracy: 0.0553\n",
            "Epoch 47/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2277 - accuracy: 0.3120 - val_loss: 9.0487 - val_accuracy: 0.0493\n",
            "Epoch 48/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1968 - accuracy: 0.3177 - val_loss: 8.9841 - val_accuracy: 0.0542\n",
            "Epoch 49/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1808 - accuracy: 0.3189 - val_loss: 9.1103 - val_accuracy: 0.0484\n",
            "Epoch 50/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1562 - accuracy: 0.3243 - val_loss: 9.3075 - val_accuracy: 0.0514\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 9.1937 - accuracy: 0.0497\n",
            "Test Loss: 9.193650245666504\n",
            "Test Accuracy: 0.04968944191932678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_FastText, \"thee\", 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdSYCT0vg3ST",
        "outputId": "92ea4871-4d0d-4c08-97ba-d85948f031da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "thee i'll i am a weary but two watched night and did perceive not sworn two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_FastText, \"Wherefore art thou \", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SQkzpUch8Oz",
        "outputId": "9c06f985-a377-463c-9c3c-6df0fe9ee00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Wherefore art thou  not thy low thy low thy low thy foe thou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMVwqjcuN1Un",
        "outputId": "dafbc47d-5787-443d-8399-47049fd7610e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedding_matrix = np.zeros((total_words, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model:\n",
        "        embedding_vector = word2vec_model[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "dyjTTEEqN8bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def transformer_model_modified_Word2Vec(total_words, max_seq_len):\n",
        "    d_model = 300\n",
        "    num_heads = 4\n",
        "    ff_dim = 128\n",
        "\n",
        "    inputs = Input(shape=(max_seq_len-1,))\n",
        "\n",
        "    # Word2Vec Word embedding\n",
        "    embedding_layer = Embedding(total_words, d_model, weights=[embedding_matrix], trainable=False)(inputs)\n",
        "    # Muti head attention\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer)\n",
        "    # connection\n",
        "    attn_output = tf.keras.layers.Add()([attn_output, embedding_layer])\n",
        "    # Normailzation\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "\n",
        "    # feed forward network\n",
        "    ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
        "\n",
        "    ffn_output = tf.keras.layers.Add()([ffn_output, attn_output])\n",
        "    # Normailzation\n",
        "    seq_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(ffn_output)\n",
        "\n",
        "    # outputlayer\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "hFYZw1bZOren"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec Model\n",
        "transformer_model_modified_Word2Vec = transformer_model_modified_Word2Vec(total_words, max_seq_len)\n",
        "\n",
        "transformer_model_modified_Word2Vec.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "transformer_model_modified_Word2Vec.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLcMgjJRPlLX",
        "outputId": "4a94a2a4-09d2-4e43-eb67-3ef7ec1d17c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 67)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)     (None, 67, 300)              2709000   ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 67, 300)              1443900   ['embedding_4[0][0]',         \n",
            " ltiHeadAttention)                                                   'embedding_4[0][0]']         \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 67, 300)              0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'embedding_4[0][0]']         \n",
            "                                                                                                  \n",
            " layer_normalization_8 (Lay  (None, 67, 300)              600       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 67, 128)              38528     ['layer_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 67, 300)              38700     ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 67, 300)              0         ['dense_13[0][0]',            \n",
            "                                                                     'layer_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " layer_normalization_9 (Lay  (None, 67, 300)              600       ['add_9[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)           (None, 300)                  0         ['layer_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 9030)                 2718030   ['lambda_4[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6949358 (26.51 MB)\n",
            "Trainable params: 4240358 (16.18 MB)\n",
            "Non-trainable params: 2709000 (10.33 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec model training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8\n",
        "history = transformer_model_modified_Word2Vec.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6bUDlH3Ps3O",
        "outputId": "0f3d9f94-e6eb-4004-ff8e-aef3abeb55b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.8909 - accuracy: 0.0811 - val_loss: 6.9571 - val_accuracy: 0.0747\n",
            "Epoch 2/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.6030 - accuracy: 0.0830 - val_loss: 7.0312 - val_accuracy: 0.0771\n",
            "Epoch 3/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.4178 - accuracy: 0.0937 - val_loss: 7.1259 - val_accuracy: 0.0707\n",
            "Epoch 4/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.2873 - accuracy: 0.0995 - val_loss: 7.2528 - val_accuracy: 0.0721\n",
            "Epoch 5/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.1682 - accuracy: 0.1074 - val_loss: 7.2135 - val_accuracy: 0.0665\n",
            "Epoch 6/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 5.0495 - accuracy: 0.1117 - val_loss: 7.3696 - val_accuracy: 0.0692\n",
            "Epoch 7/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.9150 - accuracy: 0.1183 - val_loss: 7.4693 - val_accuracy: 0.0713\n",
            "Epoch 8/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.7812 - accuracy: 0.1259 - val_loss: 7.4888 - val_accuracy: 0.0610\n",
            "Epoch 9/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.6417 - accuracy: 0.1370 - val_loss: 7.5681 - val_accuracy: 0.0644\n",
            "Epoch 10/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.5127 - accuracy: 0.1465 - val_loss: 7.6872 - val_accuracy: 0.0630\n",
            "Epoch 11/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.3866 - accuracy: 0.1582 - val_loss: 7.7192 - val_accuracy: 0.0673\n",
            "Epoch 12/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.2811 - accuracy: 0.1709 - val_loss: 7.8585 - val_accuracy: 0.0565\n",
            "Epoch 13/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.1887 - accuracy: 0.1807 - val_loss: 8.0395 - val_accuracy: 0.0610\n",
            "Epoch 14/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.0985 - accuracy: 0.1928 - val_loss: 8.1107 - val_accuracy: 0.0573\n",
            "Epoch 15/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 4.0274 - accuracy: 0.2017 - val_loss: 8.1304 - val_accuracy: 0.0599\n",
            "Epoch 16/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.9577 - accuracy: 0.2104 - val_loss: 8.1634 - val_accuracy: 0.0625\n",
            "Epoch 17/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.8968 - accuracy: 0.2167 - val_loss: 8.4533 - val_accuracy: 0.0529\n",
            "Epoch 18/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.8491 - accuracy: 0.2248 - val_loss: 8.4279 - val_accuracy: 0.0484\n",
            "Epoch 19/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.8028 - accuracy: 0.2301 - val_loss: 8.4625 - val_accuracy: 0.0519\n",
            "Epoch 20/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.7498 - accuracy: 0.2402 - val_loss: 8.4309 - val_accuracy: 0.0565\n",
            "Epoch 21/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.7079 - accuracy: 0.2424 - val_loss: 8.5598 - val_accuracy: 0.0572\n",
            "Epoch 22/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6737 - accuracy: 0.2480 - val_loss: 8.4933 - val_accuracy: 0.0515\n",
            "Epoch 23/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6406 - accuracy: 0.2526 - val_loss: 8.5247 - val_accuracy: 0.0611\n",
            "Epoch 24/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.6064 - accuracy: 0.2590 - val_loss: 8.6169 - val_accuracy: 0.0552\n",
            "Epoch 25/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5872 - accuracy: 0.2605 - val_loss: 8.5376 - val_accuracy: 0.0584\n",
            "Epoch 26/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5442 - accuracy: 0.2676 - val_loss: 8.7504 - val_accuracy: 0.0535\n",
            "Epoch 27/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5241 - accuracy: 0.2702 - val_loss: 8.5600 - val_accuracy: 0.0559\n",
            "Epoch 28/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.5024 - accuracy: 0.2752 - val_loss: 8.8691 - val_accuracy: 0.0503\n",
            "Epoch 29/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4720 - accuracy: 0.2756 - val_loss: 8.8178 - val_accuracy: 0.0569\n",
            "Epoch 30/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4491 - accuracy: 0.2822 - val_loss: 8.9577 - val_accuracy: 0.0483\n",
            "Epoch 31/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4281 - accuracy: 0.2855 - val_loss: 8.9185 - val_accuracy: 0.0575\n",
            "Epoch 32/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.4112 - accuracy: 0.2879 - val_loss: 8.8766 - val_accuracy: 0.0522\n",
            "Epoch 33/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3917 - accuracy: 0.2917 - val_loss: 8.7929 - val_accuracy: 0.0534\n",
            "Epoch 34/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3601 - accuracy: 0.2947 - val_loss: 9.0059 - val_accuracy: 0.0541\n",
            "Epoch 35/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3582 - accuracy: 0.2971 - val_loss: 8.8687 - val_accuracy: 0.0493\n",
            "Epoch 36/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3275 - accuracy: 0.3001 - val_loss: 9.1107 - val_accuracy: 0.0477\n",
            "Epoch 37/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.3201 - accuracy: 0.3021 - val_loss: 8.9651 - val_accuracy: 0.0508\n",
            "Epoch 38/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2991 - accuracy: 0.3071 - val_loss: 8.9893 - val_accuracy: 0.0481\n",
            "Epoch 39/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2774 - accuracy: 0.3087 - val_loss: 9.3676 - val_accuracy: 0.0469\n",
            "Epoch 40/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2687 - accuracy: 0.3097 - val_loss: 9.2691 - val_accuracy: 0.0460\n",
            "Epoch 41/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2521 - accuracy: 0.3143 - val_loss: 9.1600 - val_accuracy: 0.0495\n",
            "Epoch 42/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2366 - accuracy: 0.3165 - val_loss: 9.1597 - val_accuracy: 0.0483\n",
            "Epoch 43/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2199 - accuracy: 0.3172 - val_loss: 9.1803 - val_accuracy: 0.0504\n",
            "Epoch 44/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2070 - accuracy: 0.3207 - val_loss: 9.3725 - val_accuracy: 0.0493\n",
            "Epoch 45/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.2011 - accuracy: 0.3229 - val_loss: 9.2287 - val_accuracy: 0.0483\n",
            "Epoch 46/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1845 - accuracy: 0.3254 - val_loss: 9.0369 - val_accuracy: 0.0576\n",
            "Epoch 47/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1749 - accuracy: 0.3263 - val_loss: 9.1570 - val_accuracy: 0.0562\n",
            "Epoch 48/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1730 - accuracy: 0.3277 - val_loss: 9.2568 - val_accuracy: 0.0463\n",
            "Epoch 49/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1550 - accuracy: 0.3292 - val_loss: 9.2013 - val_accuracy: 0.0519\n",
            "Epoch 50/50\n",
            "7084/7084 [==============================] - 56s 8ms/step - loss: 3.1434 - accuracy: 0.3313 - val_loss: 9.3658 - val_accuracy: 0.0474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_Word2Vec, \"Wherefore art thou \", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSdqbfwQiTtK",
        "outputId": "33316474-1f63-4057-b9e7-b65f4cf85263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 173ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Wherefore art thou  come come come come come come come come come come\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_Word2Vec, \"thee\", 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vHELKu0ibj6",
        "outputId": "8e0ebecc-90c6-4d17-8fad-5ac456ee6db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "thee well served in the watch glory glory glory glory glory glory glory glory glory glory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From the result and preformance, the orignal transformer have the best performance,Fine-tunning the model"
      ],
      "metadata": {
        "id": "5dZTiaxijc6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import collections\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Lambda\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense, Layer, Dropout, LayerNormalization, Add\n",
        "from tensorflow.keras.layers import MultiHeadAttention"
      ],
      "metadata": {
        "id": "2BP-453Q8Sal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the strategy for distributed training\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Load and subset the data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/767project/Shakespeare_data.csv\")\n",
        "dataset = data['PlayerLine']\n",
        "subset_size = int(len(dataset) * 0.5)\n",
        "subset_indices = np.random.choice(range(len(dataset)), size=subset_size, replace=False)\n",
        "subset_dataset = dataset.iloc[subset_indices]\n",
        "dataset = subset_dataset\n",
        "\n",
        "# Clean text and tokenize\n",
        "tokenizer = Tokenizer()\n",
        "corpus = []\n",
        "original_lines = []\n",
        "lengths = []\n",
        "\n",
        "with strategy.scope():\n",
        "    for line in dataset:\n",
        "        clean_line = re.sub(r'[^a-zA-Z\\s]', '', line.lower())\n",
        "        if len(clean_line.split()) > 3:\n",
        "            corpus.append(clean_line)\n",
        "            original_lines.append(line)\n",
        "            lengths.append(len(clean_line.split()))\n",
        "\n",
        "print(\"min:\", min(lengths))\n",
        "print(\"max:\", max(lengths))\n",
        "print(\"mean:\", np.mean(lengths))\n",
        "print(\"median:\", np.median(lengths))\n",
        "print(\"90%<=:\", np.percentile(lengths, 90))\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1  # +1 for padding token\n",
        "\n",
        "# Define new_max_length\n",
        "new_max_length = int(np.percentile(lengths, 90))\n",
        "\n",
        "# Pair sequences with their original lengths and lines\n",
        "sequence_data = list(zip(sequences, original_lines, lengths))\n",
        "sequence_data.sort(key=lambda x: x[2])  # Sort by length\n",
        "\n",
        "# Define buckets\n",
        "buckets = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
        "bucket_data = collections.defaultdict(list)\n",
        "\n",
        "# Assign sequences to buckets based on length\n",
        "for seq, original, length in sequence_data:\n",
        "    bucket_idx = np.digitize([length], buckets)[0]\n",
        "    if bucket_idx >= len(buckets):\n",
        "        bucket_idx = len(buckets) - 1  # Place in the last bucket if it exceeds the max length\n",
        "    bucket_data[buckets[bucket_idx]].append(seq)\n",
        "\n",
        "def dynamic_bucketed_data_generator(bucket_data, batch_size, total_words, report_padding_ratio=False):\n",
        "    while True:\n",
        "        for bucket_length, sequences in bucket_data.items():\n",
        "            np.random.shuffle(sequences)\n",
        "            for i in range(0, len(sequences), batch_size):\n",
        "                batch = sequences[i:i + batch_size]\n",
        "                max_len_in_batch = max(len(seq) for seq in batch)\n",
        "                batch_padded = pad_sequences(batch, maxlen=max_len_in_batch, padding='post', truncating='post')\n",
        "\n",
        "                # Calculate padding ratio\n",
        "                if report_padding_ratio:\n",
        "                    total_elements = np.prod(batch_padded.shape)\n",
        "                    padded_elements = np.sum(batch_padded == 0)  # Assuming 0 is the padding token\n",
        "                    padding_ratio = padded_elements / total_elements\n",
        "\n",
        "\n",
        "                features = batch_padded[:, :-1]\n",
        "                labels = batch_padded[:, -1]\n",
        "                labels = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "                yield features, labels\n",
        "\n",
        "# Initialize bucket data structures for training, validation, and testing\n",
        "train_bucket_data = collections.defaultdict(list)\n",
        "val_bucket_data = collections.defaultdict(list)\n",
        "test_bucket_data = collections.defaultdict(list)\n",
        "\n",
        "# Prepare data for training, validation, and testing\n",
        "all_data = [seq for seqs in bucket_data.values() for seq in seqs]\n",
        "train_data, temp_data = train_test_split(all_data, test_size=0.4, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Assign sequences back to appropriate buckets\n",
        "for seq in train_data:\n",
        "    bucket_idx = np.digitize([len(seq)], buckets)[0]\n",
        "    if bucket_idx >= len(buckets):\n",
        "        bucket_idx = len(buckets) - 1\n",
        "    train_bucket_data[buckets[bucket_idx]].append(seq)\n",
        "\n",
        "for seq in val_data:\n",
        "    bucket_idx = np.digitize([len(seq)], buckets)[0]\n",
        "    if bucket_idx >= len(buckets):\n",
        "        bucket_idx = len(buckets) - 1\n",
        "    val_bucket_data[buckets[bucket_idx]].append(seq)\n",
        "\n",
        "for seq in test_data:\n",
        "    bucket_idx = np.digitize([len(seq)], buckets)[0]\n",
        "    if bucket_idx >= len(buckets):\n",
        "        bucket_idx = len(buckets) - 1\n",
        "    test_bucket_data[buckets[bucket_idx]].append(seq)\n",
        "\n",
        "# Create generators using the new bucketed data structures\n",
        "train_generator = dynamic_bucketed_data_generator(train_bucket_data, batch_size=64, total_words=total_words, report_padding_ratio=True)\n",
        "val_generator = dynamic_bucketed_data_generator(val_bucket_data, batch_size=64, total_words=total_words)\n",
        "test_generator = dynamic_bucketed_data_generator(test_bucket_data, batch_size=64, total_words=total_words)\n",
        "\n",
        "# Print total words\n",
        "print(f\"Total words: {total_words}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocNo1jShaSVi",
        "outputId": "332b6e3e-f296-496b-aabc-f1523155b81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min: 4\n",
            "max: 72\n",
            "mean: 7.853289734443123\n",
            "median: 8.0\n",
            "90%<=: 10.0\n",
            "Total words: 19744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the generator for padding ratio print\n",
        "for _ in range(5):\n",
        "    features, labels = next(train_generator)"
      ],
      "metadata": {
        "id": "1GocTK1lmjXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KAN simple version\n",
        "def create_padding_mask(seq):\n",
        "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "\n",
        "def transformer_model_with_kan(total_words, max_seq_len):\n",
        "    d_model = 64\n",
        "    num_heads = 4\n",
        "    ff_dim = 128\n",
        "\n",
        "    inputs = Input(shape=(max_seq_len,), name=\"inputs\")\n",
        "    embedding_layer = Embedding(total_words, d_model)(inputs)\n",
        "    padding_mask = create_padding_mask(inputs)\n",
        "\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer, attention_mask=padding_mask)\n",
        "\n",
        "    attn_output = tf.keras.layers.Add()([attn_output, embedding_layer])\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "    attn_output = Dropout(0.1)(attn_output)\n",
        "\n",
        "    kan_layer = KANLayer(d_model, ff_dim)\n",
        "    kan_output = kan_layer(attn_output)\n",
        "    kan_output = Dense(d_model, kernel_regularizer=l2(0.01))(kan_output)\n",
        "\n",
        "    kan_output = tf.keras.layers.Add()([kan_output, attn_output])\n",
        "    seq_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(kan_output)\n",
        "    seq_output = Dropout(0.1)(seq_output)\n",
        "\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "class SimplePolynomialLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimplePolynomialLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.coefficients = self.add_weight(shape=(input_dim, output_dim, 3), initializer='random_normal', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        sequence_length = tf.shape(inputs)[1]\n",
        "\n",
        "        x = tf.expand_dims(inputs, -1)  # Shape: (batch_size, sequence_length, input_dim, 1)\n",
        "        x2 = tf.pow(x, 2)\n",
        "        x3 = tf.pow(x, 3)\n",
        "        poly_terms = tf.concat([x, x2, x3], axis=-1)  # Shape: (batch_size, sequence_length, input_dim, 3)\n",
        "\n",
        "        # Using einsum for correct broadcasting\n",
        "        output = tf.einsum('bsij,ioj->bso', poly_terms, self.coefficients)  # Shape: (batch_size, sequence_length, output_dim)\n",
        "        return output\n",
        "\n",
        "class KANLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(KANLayer, self).__init__()\n",
        "        self.poly_layer = SimplePolynomialLayer(input_dim, output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.poly_layer(inputs)"
      ],
      "metadata": {
        "id": "QFTobsDLN4T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimplePolynomialLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimplePolynomialLayer, self).__init__()\n",
        "        self.coefficients = self.add_weight(\n",
        "            shape=(input_dim, output_dim, 3),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.expand_dims(inputs, -1)\n",
        "        x2 = tf.pow(x, 2)\n",
        "        x3 = tf.pow(x, 3)\n",
        "        poly_terms = tf.concat([x, x2, x3], axis=-1)\n",
        "        return tf.einsum('bsij,ioj->bso', poly_terms, self.coefficients)\n",
        "\n",
        "class EnhancedKANLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim, dropout_rate=0.1):\n",
        "        super(EnhancedKANLayer, self).__init__()\n",
        "        self.poly_layer = SimplePolynomialLayer(input_dim, output_dim)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "        self.norm = LayerNormalization(epsilon=1e-6)\n",
        "        self.dense = Dense(input_dim)  # Adjust dimensions\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.poly_layer(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x)\n",
        "        return self.norm(x + inputs)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    return tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def transformer_model_with_enhanced_kan(total_words, max_seq_len):\n",
        "    d_model = 64\n",
        "    num_heads = 4\n",
        "\n",
        "    inputs = Input(shape=(max_seq_len,), name=\"inputs\")\n",
        "    embedding_layer = Embedding(total_words, d_model)(inputs)\n",
        "    padding_mask = create_padding_mask(inputs)\n",
        "    transformer_block = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer, attention_mask=padding_mask)\n",
        "    attn_output = Add()([attn_output, embedding_layer])\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "\n",
        "    kan_layer = EnhancedKANLayer(d_model, d_model)\n",
        "    kan_output = kan_layer(attn_output)\n",
        "    kan_output = Add()([kan_output, attn_output])\n",
        "    seq_output = LayerNormalization(epsilon=1e-6)(kan_output)\n",
        "\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "a_tE1qVQjcTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer Orginal\n",
        "def create_padding_mask(seq):\n",
        "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "\n",
        "def transformer_model_orginal_final(total_words, max_seq_len):\n",
        "    d_model = 64\n",
        "    num_heads = 4\n",
        "    ff_dim = 128\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(max_seq_len,), name=\"inputs\")\n",
        "    # Word embedding\n",
        "    embedding_layer = Embedding(total_words, d_model)(inputs)\n",
        "    padding_mask = create_padding_mask(inputs)\n",
        "    # Multi-head attention\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "    attn_output = transformer_block(embedding_layer, embedding_layer, attention_mask=padding_mask)\n",
        "    # Connection\n",
        "    attn_output = tf.keras.layers.Add()([attn_output, embedding_layer])\n",
        "    # Normalization\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
        "    attn_output = Dropout(0.1)(attn_output)  # Add Dropout layer\n",
        "\n",
        "    # Feed forward network\n",
        "    ffn_output = tf.keras.layers.Dense(ff_dim, activation=swish)(attn_output)\n",
        "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
        "    ffn_output = Dropout(0.1)(ffn_output)  # Add Dropout layer\n",
        "\n",
        "    ffn_output = tf.keras.layers.Add()([ffn_output, attn_output])\n",
        "    # Normalization\n",
        "    seq_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(ffn_output)\n",
        "\n",
        "    # Output layer\n",
        "    final_output = Lambda(lambda x: x[:, -1, :])(seq_output)\n",
        "    outputs = Dense(total_words, activation='softmax')(final_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "CIXMq9IhhvRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KAN Transformer\n",
        "initial_learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\"\\nEpoch\", epoch+1, \"current learning rate:\", tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "transformer_model_with_kan = transformer_model_with_kan(total_words=total_words, max_seq_len=new_max_length-1)\n",
        "\n",
        "# 编译模型\n",
        "model = transformer_model_with_kan(total_words=total_words, max_seq_len=new_max_length-1)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 打印模型摘要\n",
        "model.summary()\n",
        "\n",
        "# 训练模型\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_data) // batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_data) // batch_size,\n",
        "    callbacks=[PrintLR()]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "HBb3cZupyPIq",
        "outputId": "f1c0c4d1-eb3a-41de-a9cc-3a5960835d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The first argument to `Layer.call` must always be passed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-00cdff0f15a0>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 编译模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_model_with_kan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_max_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m model.compile(\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/layer_utils.py\u001b[0m in \u001b[0;36msplit_out_first_arg\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;34m\"The first argument to `Layer.call` must always be passed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\"\\nEpoch\", epoch+1, \"current learning rate:\", tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "transformer_model_orginal_final = transformer_model_orginal_final(total_words=total_words, max_seq_len=new_max_length-1)\n",
        "\n",
        "transformer_model_orginal_final.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "transformer_model_orginal_final.summary()"
      ],
      "metadata": {
        "id": "EmCV4P-kp5t4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e761c4-cff5-4472-a734-b8b4999b9889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, 9)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.math.equal_3 (TFOpLambd  (None, 9)                    0         ['inputs[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.cast_3 (TFOpLambda)      (None, 9)                    0         ['tf.math.equal_3[0][0]']     \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 9, 64)                1263296   ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3  (None, 1, 1, 9)              0         ['tf.cast_3[0][0]']           \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 9, 64)                66368     ['embedding_3[0][0]',         \n",
            " ltiHeadAttention)                                                   'embedding_3[0][0]',         \n",
            "                                                                     'tf.__operators__.getitem_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 9, 64)                0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 9, 64)                128       ['add_6[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 9, 64)                0         ['layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 9, 128)               8320      ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 9, 64)                8256      ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 9, 64)                0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 9, 64)                0         ['dropout_7[0][0]',           \n",
            "                                                                     'dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 9, 64)                128       ['add_7[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)           (None, 64)                   0         ['layer_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 19739)                1283035   ['lambda_3[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2629531 (10.03 MB)\n",
            "Trainable params: 2629531 (10.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = transformer_model_orginal_final.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_data) // batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_data) // batch_size,\n",
        "    callbacks=[lr_scheduler, PrintLR()]\n",
        ")"
      ],
      "metadata": {
        "id": "b4hYjk-IzZg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b97a00-d252-4e74-bb18-e62927e93c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 7.1633 - accuracy: 0.6755\n",
            "Epoch 1 current learning rate: 1e-04\n",
            "473/473 [==============================] - 24s 45ms/step - loss: 7.1633 - accuracy: 0.6755 - val_loss: 4.6705 - val_accuracy: 0.7076 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "471/473 [============================>.] - ETA: 0s - loss: 3.3946 - accuracy: 0.7114\n",
            "Epoch 2 current learning rate: 1e-04\n",
            "473/473 [==============================] - 14s 30ms/step - loss: 3.3915 - accuracy: 0.7115 - val_loss: 2.8866 - val_accuracy: 0.7129 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.6382 - accuracy: 0.7142\n",
            "Epoch 3 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 28ms/step - loss: 2.6382 - accuracy: 0.7142 - val_loss: 2.7167 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.4467 - accuracy: 0.7139\n",
            "Epoch 4 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.4467 - accuracy: 0.7139 - val_loss: 2.6095 - val_accuracy: 0.7116 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "471/473 [============================>.] - ETA: 0s - loss: 2.3544 - accuracy: 0.7114\n",
            "Epoch 5 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.3532 - accuracy: 0.7115 - val_loss: 2.6204 - val_accuracy: 0.7084 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.2500 - accuracy: 0.7146\n",
            "Epoch 6 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.2500 - accuracy: 0.7146 - val_loss: 2.5997 - val_accuracy: 0.7120 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.1800 - accuracy: 0.7159\n",
            "Epoch 7 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.1800 - accuracy: 0.7159 - val_loss: 2.5742 - val_accuracy: 0.7163 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.1625 - accuracy: 0.7124\n",
            "Epoch 8 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.1625 - accuracy: 0.7124 - val_loss: 2.6710 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.0937 - accuracy: 0.7164\n",
            "Epoch 9 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.0937 - accuracy: 0.7164 - val_loss: 2.6231 - val_accuracy: 0.7151 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.0708 - accuracy: 0.7147\n",
            "Epoch 10 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.0708 - accuracy: 0.7147 - val_loss: 2.6039 - val_accuracy: 0.7132 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 2.0254 - accuracy: 0.7152\n",
            "Epoch 11 current learning rate: 1e-04\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 2.0254 - accuracy: 0.7152 - val_loss: 2.7083 - val_accuracy: 0.7057 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9604 - accuracy: 0.7190\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 12 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.9604 - accuracy: 0.7190 - val_loss: 2.6657 - val_accuracy: 0.7097 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9355 - accuracy: 0.7165\n",
            "Epoch 13 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.9355 - accuracy: 0.7165 - val_loss: 2.6427 - val_accuracy: 0.7141 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9413 - accuracy: 0.7142\n",
            "Epoch 14 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.9413 - accuracy: 0.7142 - val_loss: 2.6996 - val_accuracy: 0.7059 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9333 - accuracy: 0.7149\n",
            "Epoch 15 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.9333 - accuracy: 0.7149 - val_loss: 2.6346 - val_accuracy: 0.7122 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9144 - accuracy: 0.7170\n",
            "Epoch 16 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.9144 - accuracy: 0.7170 - val_loss: 2.7404 - val_accuracy: 0.7043 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9106 - accuracy: 0.7172\n",
            "Epoch 17 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.9106 - accuracy: 0.7172 - val_loss: 2.7043 - val_accuracy: 0.7036 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9203 - accuracy: 0.7146\n",
            "Epoch 18 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.9203 - accuracy: 0.7146 - val_loss: 2.6648 - val_accuracy: 0.7099 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8780 - accuracy: 0.7202\n",
            "Epoch 19 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8780 - accuracy: 0.7202 - val_loss: 2.6834 - val_accuracy: 0.7091 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.9015 - accuracy: 0.7167\n",
            "Epoch 20 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.9015 - accuracy: 0.7167 - val_loss: 2.7214 - val_accuracy: 0.7061 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8982 - accuracy: 0.7161\n",
            "Epoch 21 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8982 - accuracy: 0.7161 - val_loss: 2.6655 - val_accuracy: 0.7092 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8886 - accuracy: 0.7162\n",
            "Epoch 22 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8886 - accuracy: 0.7162 - val_loss: 2.7238 - val_accuracy: 0.7066 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8793 - accuracy: 0.7177\n",
            "Epoch 23 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8793 - accuracy: 0.7177 - val_loss: 2.7036 - val_accuracy: 0.7065 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8696 - accuracy: 0.7181\n",
            "Epoch 24 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8696 - accuracy: 0.7181 - val_loss: 2.7291 - val_accuracy: 0.7053 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8637 - accuracy: 0.7179\n",
            "Epoch 25 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8629 - accuracy: 0.7180 - val_loss: 2.7328 - val_accuracy: 0.7067 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8664 - accuracy: 0.7176\n",
            "Epoch 26 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8662 - accuracy: 0.7176 - val_loss: 2.7300 - val_accuracy: 0.7070 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.7737 - accuracy: 0.7302\n",
            "Epoch 27 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.7834 - accuracy: 0.7287 - val_loss: 2.7619 - val_accuracy: 0.7078 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.7604 - accuracy: 0.7323\n",
            "Epoch 28 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.7701 - accuracy: 0.7308 - val_loss: 2.8217 - val_accuracy: 0.7041 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7558 - accuracy: 0.7320\n",
            "Epoch 29 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7558 - accuracy: 0.7320 - val_loss: 2.8765 - val_accuracy: 0.6992 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8176 - accuracy: 0.7220\n",
            "Epoch 30 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8141 - accuracy: 0.7226 - val_loss: 2.8917 - val_accuracy: 0.7009 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8673 - accuracy: 0.7142\n",
            "Epoch 31 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8673 - accuracy: 0.7142 - val_loss: 2.8865 - val_accuracy: 0.7005 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8726 - accuracy: 0.7118\n",
            "Epoch 32 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8709 - accuracy: 0.7121 - val_loss: 2.8860 - val_accuracy: 0.7001 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8568 - accuracy: 0.7139\n",
            "Epoch 33 current learning rate: 1e-05\n",
            "473/473 [==============================] - 13s 27ms/step - loss: 1.8532 - accuracy: 0.7144 - val_loss: 2.8875 - val_accuracy: 0.6972 - lr: 1.0000e-05\n",
            "Epoch 34/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8535 - accuracy: 0.7138\n",
            "Epoch 34 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8535 - accuracy: 0.7138 - val_loss: 2.8496 - val_accuracy: 0.7005 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8440 - accuracy: 0.7144\n",
            "Epoch 35 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8440 - accuracy: 0.7144 - val_loss: 2.6123 - val_accuracy: 0.7247 - lr: 1.0000e-05\n",
            "Epoch 36/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8445 - accuracy: 0.7137\n",
            "Epoch 36 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8445 - accuracy: 0.7137 - val_loss: 2.5343 - val_accuracy: 0.7330 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8501 - accuracy: 0.7126\n",
            "Epoch 37 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8501 - accuracy: 0.7126 - val_loss: 2.6311 - val_accuracy: 0.7211 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.8334 - accuracy: 0.7148\n",
            "Epoch 38 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8313 - accuracy: 0.7152 - val_loss: 2.7922 - val_accuracy: 0.7031 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8144 - accuracy: 0.7168\n",
            "Epoch 39 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8144 - accuracy: 0.7168 - val_loss: 2.8127 - val_accuracy: 0.6995 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.8040 - accuracy: 0.7186\n",
            "Epoch 40 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.8040 - accuracy: 0.7186 - val_loss: 2.8259 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "471/473 [============================>.] - ETA: 0s - loss: 1.7833 - accuracy: 0.7202\n",
            "Epoch 41 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7817 - accuracy: 0.7204 - val_loss: 2.8137 - val_accuracy: 0.7021 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7911 - accuracy: 0.7190\n",
            "Epoch 42 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 25ms/step - loss: 1.7911 - accuracy: 0.7190 - val_loss: 2.7956 - val_accuracy: 0.7015 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7820 - accuracy: 0.7191\n",
            "Epoch 43 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7820 - accuracy: 0.7191 - val_loss: 2.8384 - val_accuracy: 0.7008 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "472/473 [============================>.] - ETA: 0s - loss: 1.7702 - accuracy: 0.7204\n",
            "Epoch 44 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7692 - accuracy: 0.7206 - val_loss: 2.8580 - val_accuracy: 0.6974 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7736 - accuracy: 0.7196\n",
            "Epoch 45 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7736 - accuracy: 0.7196 - val_loss: 2.8230 - val_accuracy: 0.7032 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7589 - accuracy: 0.7216\n",
            "Epoch 46 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7589 - accuracy: 0.7216 - val_loss: 2.8536 - val_accuracy: 0.6965 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7540 - accuracy: 0.7215\n",
            "Epoch 47 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7540 - accuracy: 0.7215 - val_loss: 2.7928 - val_accuracy: 0.7053 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7709 - accuracy: 0.7188\n",
            "Epoch 48 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7709 - accuracy: 0.7188 - val_loss: 2.8470 - val_accuracy: 0.6968 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "471/473 [============================>.] - ETA: 0s - loss: 1.7592 - accuracy: 0.7208\n",
            "Epoch 49 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7582 - accuracy: 0.7208 - val_loss: 2.8662 - val_accuracy: 0.7008 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "473/473 [==============================] - ETA: 0s - loss: 1.7304 - accuracy: 0.7243\n",
            "Epoch 50 current learning rate: 1e-05\n",
            "473/473 [==============================] - 12s 26ms/step - loss: 1.7304 - accuracy: 0.7243 - val_loss: 2.8713 - val_accuracy: 0.6963 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_save_path = '/content/drive/My Drive/My Models/transformer_model_modified_final.h5'\n",
        "\n",
        "\n",
        "transformer_model_modified_final.save(model_save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef6yLex7fqUE",
        "outputId": "76a2a56c-85a6-46e1-eaa4-6851e808bc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir('/content/drive/My Drive/My Models'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYt1UE70fv9k",
        "outputId": "a989f84e-ba10-4873-be4d-eb0590f929b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['transformer_model_modified_final.h5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def test_generator(model, seed_text, num_words, temperature=1.0):\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=new_max_length-1, padding='post')\n",
        "\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]  # Get the first sequence\n",
        "        # Apply temperature scaling\n",
        "        predictions = np.log(predicted_probs + 1e-10) / temperature  # Adding a small constant to avoid log(0)\n",
        "        exp_predictions = np.exp(predictions)\n",
        "        predicted_probs = exp_predictions / np.sum(exp_predictions)\n",
        "\n",
        "        # Ensure <pad> token (usually index 0) is never chosen\n",
        "        predicted_probs[0] = 0\n",
        "        predicted_probs = predicted_probs / np.sum(predicted_probs)  # Re-normalize probabilities\n",
        "\n",
        "        # Select a word based on the probability distribution\n",
        "        try:\n",
        "            predicted_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
        "        except ValueError:\n",
        "            print(\"Error: Probability distribution does not sum to 1.\")\n",
        "            continue\n",
        "\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, '')\n",
        "\n",
        "        if predicted_word == '':\n",
        "            print(\"No valid prediction; check the model's output.\")\n",
        "            break\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "        print(\"Generated so far:\", seed_text)  # Print the generated text so far\n",
        "\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "s4TBIlzQc1py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_final, \"Wherefore art thou \", 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "FccNk-i5f08E",
        "outputId": "593e1866-4421-47a7-ce43-5238a3ed2983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated so far: Wherefore art thou  fallst\n",
            "Generated so far: Wherefore art thou  fallst commonwealth\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as i\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as i am\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as i am i\n",
            "Generated so far: Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as i am i am\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wherefore art thou  fallst commonwealth unspeakable foulness out my fond of fold night another hit of another flesh as i am i am'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_final, \"extremities he endured\", 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "CA9d2S8PgBmF",
        "outputId": "13764289-f1a0-4762-d0f5-3c17de71bd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated so far: extremities he endured kates\n",
            "Generated so far: extremities he endured kates traditional\n",
            "Generated so far: extremities he endured kates traditional nedars\n",
            "Generated so far: extremities he endured kates traditional nedars felt\n",
            "Generated so far: extremities he endured kates traditional nedars felt there\n",
            "Generated so far: extremities he endured kates traditional nedars felt there can\n",
            "Generated so far: extremities he endured kates traditional nedars felt there can never\n",
            "Generated so far: extremities he endured kates traditional nedars felt there can never foul\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'extremities he endured kates traditional nedars felt there can never foul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(transformer_model_modified_final, \"thee\", 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "_nOh7JphgPsk",
        "outputId": "a74ee53c-fcc4-496b-808a-212df9f5008a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated so far: thee prefixd\n",
            "Generated so far: thee prefixd allottery\n",
            "Generated so far: thee prefixd allottery fingering\n",
            "Generated so far: thee prefixd allottery fingering newlighted\n",
            "Generated so far: thee prefixd allottery fingering newlighted induce\n",
            "Generated so far: thee prefixd allottery fingering newlighted induce bridegroom\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thee prefixd allottery fingering newlighted induce bridegroom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}